---
# Common configuration for all control plane nodes
# This patch is applied to all 3 control plane nodes during generation

machine:
  # Install configuration
  install:
    disk: /dev/nvme1n1  # 256GB system disk
    wipe: false

  # Network configuration
  network:
    interfaces:
      - interface: enp5s0f3u2
        dhcp: true
    nameservers:
      - 192.168.40.1
      - 1.1.1.1
      - 1.0.0.1

  # Kubelet configuration for Rook-Ceph
  kubelet:
    defaultRuntimeSeccompProfileEnabled: true
    disableManifestsDirectory: true
    extraConfig:
      serializeImagePulls: false
    nodeIP:
      validSubnets:
        - 192.168.40.0/24

  # Features
  features:
    rbac: true
    kubernetesTalosAPIAccess:
      enabled: true
      allowedRoles:
        - os:admin
      allowedKubernetesNamespaces:
        - kube-system
    diskQuotaSupport: true
    kubePrism:
      enabled: true
      port: 7445
    hostDNS:
      enabled: true
      forwardKubeDNSToHost: true
      resolveMemberNames: true

  # System disk partitions - Mount 1TB data disk for Ceph
  disks:
    - device: /dev/nvme0n1  # 1TB data disk for Ceph
      partitions:
        - mountpoint: /var/mnt/ceph

  # Sysctls for networking
  sysctls:
    fs.inotify.max_user_instances: "8192"
    fs.inotify.max_user_watches: "1048576"
    net.core.default_qdisc: fq
    net.core.rmem_max: "67108864"
    net.core.wmem_max: "67108864"
    net.ipv4.neigh.default.gc_thresh1: "4096"
    net.ipv4.neigh.default.gc_thresh2: "8192"
    net.ipv4.neigh.default.gc_thresh3: "16384"
    net.ipv4.ping_group_range: 0 2147483647
    net.ipv4.tcp_congestion_control: bbr
    net.ipv4.tcp_fastopen: "3"
    net.ipv4.tcp_mtu_probing: "1"
    net.ipv4.tcp_rmem: 4096 87380 33554432
    net.ipv4.tcp_slow_start_after_idle: "0"
    net.ipv4.tcp_window_scaling: "1"
    net.ipv4.tcp_wmem: 4096 65536 33554432
    user.max_user_namespaces: "11255"

# Cluster configuration
cluster:
  # Discovery
  discovery:
    enabled: true
    registries:
      kubernetes:
        disabled: false
      service:
        disabled: false

  # Network
  network:
    cni:
      name: none  # Using Cilium
    dnsDomain: cluster.local
    podSubnets:
      - 10.244.0.0/16
    serviceSubnets:
      - 10.96.0.0/12

  # Proxy configuration
  proxy:
    disabled: true  # Using Cilium kube-proxy replacement

  # Scheduler configuration
  scheduler:
    config:
      apiVersion: kubescheduler.config.k8s.io/v1
      kind: KubeSchedulerConfiguration

  # Controller manager
  controllerManager:
    extraArgs:
      bind-address: 0.0.0.0

  # API server configuration
  apiServer:
    certSANs:
      - 192.168.40.11
      - 192.168.40.12
      - 192.168.40.13
    extraArgs:
      feature-gates: MixedProtocolLBService=true,ServerSideApply=true

  # Etcd configuration (3-node HA)
  etcd:
    advertisedSubnets:
      - 192.168.40.0/24

  # Allow scheduling on control plane nodes (no workers)
  allowSchedulingOnControlPlanes: true

  # Inline manifests for critical components that need to run before CNI
  inlineManifests: []
