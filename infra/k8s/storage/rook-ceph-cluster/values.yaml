monitoring:
  enabled: true
  createPrometheusRules: true

toolbox:
  enabled: true

route:
  dashboard:
    host:
      name: rook.atoca.house
      path: /
      pathType: PathPrefix
    parentRefs:
      - name: atoca-house-internal
        namespace: kube-system

operatorNamespace: rook-ceph

cephClusterSpec:
  cephVersion:
    image: quay.io/ceph/ceph:v20.2.0
  cephConfig:
    global:
      bdev_enable_discard: "true" # quote
      bdev_async_discard_threads: "1" # quote
      osd_class_update_on_start: "false" # quote
      device_failure_prediction_mode: local # requires mgr module
  cleanupPolicy:
    wipeDevicesFromOtherClusters: true
  crashCollector:
    disable: false
  csi:
    readAffinity:
      enabled: true
  dashboard:
    enabled: true
    urlPrefix: /
    ssl: false
    prometheusEndpoint: http://kube-prometheus-stack-moni-prometheus.monitoring.svc.cluster.local:9090
  mgr:
    modules:
      - name: diskprediction_local
        enabled: true
      - name: insights
        enabled: true
      - name: pg_autoscaler
        enabled: true
      - name: rook
        enabled: true
  network:
    provider: host
    addressRanges:
      public:
        - 192.168.40.0/24
      cluster:
        - 192.168.40.0/24
    connections:
      requireMsgr2: true
  resources:
    osd:
      limits:
        memory: 8Gi
  storage:
    useAllNodes: false
    useAllDevices: false
    nodes:
      - name: "node-01"
        devices:
          - name: "/dev/disk/by-id/nvme-FIKWOT_FN955_1TB_AA245040550"
      - name: "node-02"
        devices:
          - name: "/dev/disk/by-id/nvme-FIKWOT_FN955_1TB_AA245040379"
      - name: "node-03"
        devices:
          - name: "/dev/disk/by-id/nvme-FIKWOT_FN955_1TB_AA245040603"
      - name: "node-04"
        devices:
          - name: "/dev/disk/by-id/nvme-Samsung_SSD_980_PRO_1TB_S5GXNS0X326250J"
    config:
      osdsPerDevice: "1"

# Storage Classes
cephBlockPools:
  - name: ceph-blockpool
    spec:
      failureDomain: host  # Replicate across hosts
      replicated:
        size: 3
    storageClass:
      enabled: true
      name: ceph-block
      isDefault: true  # Make this the default storage class
      reclaimPolicy: Delete
      allowVolumeExpansion: true
      volumeBindingMode: Immediate
      mountOptions:
        - discard
      parameters:
        compression_mode: aggressive
        compression_algorithm: zstd
        imageFormat: "2"
        imageFeatures: layering,fast-diff,object-map,deep-flatten,exclusive-lock
        csi.storage.k8s.io/provisioner-secret-name: rook-csi-rbd-provisioner
        csi.storage.k8s.io/provisioner-secret-namespace: rook-ceph
        csi.storage.k8s.io/controller-expand-secret-name: rook-csi-rbd-provisioner
        csi.storage.k8s.io/controller-expand-secret-namespace: rook-ceph
        csi.storage.k8s.io/node-stage-secret-name: rook-csi-rbd-node
        csi.storage.k8s.io/node-stage-secret-namespace: rook-ceph
        csi.storage.k8s.io/fstype: ext4

cephBlockPoolsVolumeSnapshotClass:
  enabled: true
  name: csi-ceph-blockpool
  isDefault: false
  deletionPolicy: Delete


cephFileSystems: []
cephObjectStores: []
