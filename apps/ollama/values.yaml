ollama:
  # -- List of models to pull at container startup
  models:
    - tinyllama
    - llama3
    - gemma2

  gpu:
    enabled: true
    type: 'nvidia'
    number: 1

ingress:
  enabled: true
  className: nginx
  annotations:
    cert-manager.io/cluster-issuer: "cloudflare-prod"
  hosts:
    - host: ollama.atoca.house
      paths:
        - path: /
          pathType: Prefix
  tls:
    - hosts:
      - ollama.atoca.house
      secretName: ollama-tls

nodeSelector:
  dedicated: ollama

tolerations:
  - key: "dedicated"
    operator: "Equal"
    value: "ollama"
    effect: "NoSchedule"