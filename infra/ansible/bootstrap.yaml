---
- name: Bootstrap Talos Kubernetes cluster with ArgoCD GitOps
  hosts: localhost
  gather_facts: yes

  vars:
    talos_dir: "{{ lookup('env', 'PWD') }}/infra/talos"
    age_config_dir: "{{ ansible_env.HOME }}/.config/age"
    talos_config_file: "{{ ansible_env.HOME }}/.talos/config"
    op_argocd_redis_id: "Private/atoca-house-k8s-argocd-redis/credential"
    argocd_redis_token_name: "argocd-redis"
    argocd_namespace: "argocd"
    # All 3 nodes are control planes (no workers)
    control_plane_nodes:
      - name: node-01
        ip: 192.168.178.201
      - name: node-02
        ip: 192.168.178.202
      - name: node-03
        ip: 192.168.178.203
    # Bootstrap node (first control plane)
    bootstrap_node: 192.168.178.201

  tasks:
    # ============================================================================
    # Phase 1: Setup Age encryption for SOPS
    # ============================================================================
    - name: Create age config directory
      ansible.builtin.file:
        path: "{{ age_config_dir }}"
        state: directory
        mode: '0700'

    - name: Read age key from 1Password and store it in the config
      shell: "op read op://K8s/age-key/age.key > {{ age_config_dir }}/age.key"
      args:
        creates: "{{ age_config_dir }}/age.key"

    - name: Set permissions for age key
      ansible.builtin.file:
        path: "{{ age_config_dir }}/age.key"
        mode: '0600'

    # ============================================================================
    # Phase 2: Deploy Talos OS Configuration (3 Control Planes)
    # ============================================================================
    - name: Decrypt Talos controlplane files
      shell: "sops --config {{ lookup('env', 'PWD') }}/.sops.yaml -d {{ talos_dir }}/controlplane-{{ item.name }}.enc.yaml > {{ talos_dir }}/controlplane-{{ item.name }}.yaml"
      args:
        creates: "{{ talos_dir }}/controlplane-{{ item.name }}.yaml"
      environment:
        SOPS_AGE_KEY_FILE: "{{ age_config_dir }}/age.key"
      loop: "{{ control_plane_nodes }}"

    - name: Apply Talos controlplane configs to all nodes
      shell: "talosctl apply-config --insecure --nodes {{ item.ip }} --file {{ talos_dir }}/controlplane-{{ item.name }}.yaml"
      loop: "{{ control_plane_nodes }}"

    - name: Wait for 30 seconds for Talos to initialize
      ansible.builtin.pause:
        seconds: 30

    - name: Bootstrap first control plane node
      shell: "talosctl bootstrap -n {{ bootstrap_node }}"

    - name: Wait for first control plane to be ready
      shell: |
        talosctl kubeconfig {{ lookup('env', 'HOME') }} -f -n {{ bootstrap_node }}
        kubectl --kubeconfig={{ lookup('env', 'HOME') }}/kubeconfig get nodes {{ control_plane_nodes[0].name }} -o jsonpath='{.status.conditions[?(@.type=="Ready")].status}' | grep True
      retries: 20
      delay: 30
      register: first_node_ready
      until: first_node_ready.rc == 0

    - name: Wait for all control plane nodes to join and be ready
      shell: "kubectl --kubeconfig={{ lookup('env', 'HOME') }}/kubeconfig get nodes --selector node-role.kubernetes.io/control-plane -o jsonpath='{.items[*].status.conditions[?(@.type==\"Ready\")].status}' | grep -v False"
      retries: 20
      delay: 30
      register: all_nodes_ready
      until: all_nodes_ready.rc == 0

    - name: Generate kubeconfig for the cluster
      shell: "talosctl kubeconfig -f -n {{ bootstrap_node }}"

    - name: Remove decrypted Talos YAML files
      ansible.builtin.file:
        path: "{{ talos_dir }}/{{ item }}"
        state: absent
      loop:
        - controlplane-node-01.yaml
        - controlplane-node-02.yaml
        - controlplane-node-03.yaml

    # ============================================================================
    # Phase 3: Install Core Infrastructure (CNI)
    # ============================================================================
    - name: Apply Cilium CNI (critical - required for networking)
      shell: "kubectl kustomize --enable-helm {{ lookup('env', 'PWD') }}/infra/k8s/networking/cilium | kubectl apply -f -"

    - name: Wait for Cilium to be ready
      shell: |
        kubectl wait --for=condition=ready pod -l k8s-app=cilium -n kube-system --timeout=300s &&
        kubectl wait --for=condition=ready pod -l k8s-app=cilium-operator -n kube-system --timeout=300s
      retries: 10
      delay: 30
      register: cilium_ready
      until: cilium_ready.rc == 0

    - name: Verify all nodes are Ready after CNI installation
      shell: "kubectl get nodes -o jsonpath='{.items[*].status.conditions[?(@.type==\"Ready\")].status}' | grep -v False"
      retries: 10
      delay: 15
      register: nodes_ready
      until: nodes_ready.rc == 0

    # ============================================================================
    # Phase 4: Install Sealed Secrets (required for secret management)
    # ============================================================================
    - name: Apply Sealed Secrets
      shell: "kubectl kustomize --enable-helm {{ lookup('env', 'PWD') }}/infra/k8s/security/sealed-secrets | kubectl apply -f -"

    - name: Wait for Sealed Secrets controller to be ready
      shell: "kubectl wait --for=condition=available deployment/sealed-secrets-controller -n sealed-secrets --timeout=300s"
      retries: 10
      delay: 30
      register: sealed_secrets_ready
      until: sealed_secrets_ready.rc == 0

    # ============================================================================
    # Phase 5: Install ArgoCD
    # ============================================================================
    - name: Retrieve the ArgoCD Redis secret from One Password
      ansible.builtin.command:
        cmd: "op read op://{{ op_argocd_redis_id }}"
      register: argo_redis_retrieved_secret

    - name: Write the ArgoCD Redis secret to a file
      ansible.builtin.copy:
        content: "{{ argo_redis_retrieved_secret.stdout }}"
        dest: /tmp/op_argocd_redis.txt
        force: yes

    - name: Create argocd namespace
      ansible.builtin.command:
        cmd: "kubectl create namespace {{ argocd_namespace }}"
      ignore_errors: yes

    - name: Create a Kubernetes secret for argocd-redis
      ansible.builtin.command:
        cmd: "kubectl -n {{ argocd_namespace }} create secret generic {{ argocd_redis_token_name }} --dry-run=client --from-file=auth=/tmp/op_argocd_redis.txt -o yaml > /tmp/{{ argocd_redis_token_name }}.yaml"

    - name: Apply argocd-redis manifest
      ansible.builtin.command:
        cmd: "kubectl apply -f /tmp/{{ argocd_redis_token_name }}.yaml"

    - name: Remove temporary secret files
      ansible.builtin.file:
        path: "{{ item }}"
        state: absent
      loop:
        - "/tmp/{{ argocd_redis_token_name }}.yaml"
        - "/tmp/op_argocd_redis.txt"

    - name: Apply ArgoCD installation
      shell: "kubectl kustomize --enable-helm {{ lookup('env', 'PWD') }}/argocd/install | kubectl apply -f -"

    - name: Wait for ArgoCD components to be ready
      shell: |
        kubectl wait --for=condition=available deployment/argocd-server -n argocd --timeout=300s &&
        kubectl wait --for=condition=available deployment/argocd-repo-server -n argocd --timeout=300s &&
        kubectl wait --for=condition=available deployment/argocd-application-controller -n argocd --timeout=300s
      retries: 10
      delay: 30
      register: argocd_ready
      until: argocd_ready.rc == 0

    # ============================================================================
    # Phase 6: Apply ArgoCD Applications (GitOps takes over)
    # ============================================================================
    - name: Apply ArgoCD parent applications and projects
      shell: "kubectl apply -f {{ lookup('env', 'PWD') }}/argocd/applications/"

    - name: Wait for critical infrastructure parent apps to be created
      shell: "kubectl get application -n argocd {{ item }} -o jsonpath='{.metadata.name}'"
      retries: 5
      delay: 10
      register: parent_app_created
      until: parent_app_created.rc == 0
      loop:
        - infra-security
        - infra-networking
        - infra-storage

    # ============================================================================
    # Phase 7: Wait for critical infrastructure to sync
    # ============================================================================
    - name: Wait for cert-manager to be synced and healthy
      shell: |
        kubectl get application cert-manager -n argocd -o jsonpath='{.status.health.status}' | grep -q Healthy &&
        kubectl get application cert-manager -n argocd -o jsonpath='{.status.sync.status}' | grep -q Synced
      retries: 20
      delay: 30
      register: cert_manager_ready
      until: cert_manager_ready.rc == 0

    - name: Wait for external-secrets to be synced and healthy
      shell: |
        kubectl get application external-secrets -n argocd -o jsonpath='{.status.health.status}' | grep -q Healthy &&
        kubectl get application external-secrets -n argocd -o jsonpath='{.status.sync.status}' | grep -q Synced
      retries: 20
      delay: 30
      register: external_secrets_ready
      until: external_secrets_ready.rc == 0

    - name: Wait for one-password operator to be synced and healthy
      shell: |
        kubectl get application one-password -n argocd -o jsonpath='{.status.health.status}' | grep -q Healthy &&
        kubectl get application one-password -n argocd -o jsonpath='{.status.sync.status}' | grep -q Synced
      retries: 20
      delay: 30
      register: onepassword_ready
      until: onepassword_ready.rc == 0

    - name: Wait for Rook-Ceph operator to be synced and healthy
      shell: |
        kubectl get application rook-ceph-operator -n argocd -o jsonpath='{.status.health.status}' | grep -q Healthy &&
        kubectl get application rook-ceph-operator -n argocd -o jsonpath='{.status.sync.status}' | grep -q Synced
      retries: 20
      delay: 30
      register: rook_operator_ready
      until: rook_operator_ready.rc == 0

    - name: Wait for Rook-Ceph operator pods to be ready
      shell: "kubectl wait --for=condition=ready pod -l app=rook-ceph-operator -n rook-ceph --timeout=300s"
      retries: 5
      delay: 30
      register: rook_operator_pods_ready
      until: rook_operator_pods_ready.rc == 0

    - name: Wait for Rook-Ceph cluster to be synced and healthy
      shell: |
        kubectl get application rook-ceph-cluster -n argocd -o jsonpath='{.status.health.status}' | grep -q Healthy &&
        kubectl get application rook-ceph-cluster -n argocd -o jsonpath='{.status.sync.status}' | grep -q Synced
      retries: 40
      delay: 30
      register: rook_cluster_ready
      until: rook_cluster_ready.rc == 0

    - name: Wait for Ceph cluster to be healthy
      shell: "kubectl -n rook-ceph exec deploy/rook-ceph-tools -- ceph health | grep -q HEALTH_OK"
      retries: 60
      delay: 30
      register: ceph_healthy
      until: ceph_healthy.rc == 0
      ignore_errors: yes  # Cluster might not be HEALTH_OK immediately

    # ============================================================================
    # Phase 8: Bootstrap Complete
    # ============================================================================
    - name: Display bootstrap completion message
      debug:
        msg: |
          ============================================================================
          ðŸŽ‰ Bootstrap Complete! ðŸŽ‰
          ============================================================================

          Cluster Configuration:
            â€¢ 3-node HA control plane cluster
            â€¢ Nodes: node-01 (201), node-02 (202), node-03 (203)
            â€¢ All nodes are control planes (no dedicated workers)
            â€¢ Distributed storage with Rook-Ceph (3x 1TB disks)

          Core Infrastructure Installed:
            âœ“ Cilium CNI (eBPF networking with Gateway API)
            âœ“ Sealed Secrets (encrypted secret storage)
            âœ“ ArgoCD (GitOps continuous deployment)
            âœ“ Cert-Manager (automated TLS certificate management)
            âœ“ External Secrets (secret injection from 1Password)
            âœ“ 1Password Operator (secure secret management)
            âœ“ Rook-Ceph Operator (distributed storage orchestration)
            âœ“ Rook-Ceph Cluster (block/filesystem/object storage)

          ArgoCD is now managing all infrastructure and applications via GitOps.

          ============================================================================
          Quick Start Commands
          ============================================================================

          Verify Cluster:
            kubectl get nodes -o wide
            kubectl get pods --all-namespaces
            talosctl -n 192.168.178.201 health

          Access ArgoCD:
            kubectl port-forward svc/argocd-server -n argocd 8080:443
            # Username: admin
            # Password: kubectl -n argocd get secret argocd-initial-admin-secret -o jsonpath="{.data.password}" | base64 -d
            # Or via ingress: https://argocd.atoca.house

          Monitor Applications:
            kubectl get applications -n argocd
            kubectl get applications -n argocd -w  # Watch mode

          Check Ceph Storage:
            kubectl -n rook-ceph exec -it deploy/rook-ceph-tools -- ceph status
            kubectl -n rook-ceph exec -it deploy/rook-ceph-tools -- ceph df
            kubectl -n rook-ceph exec -it deploy/rook-ceph-tools -- ceph osd tree

          Access Ceph Dashboard:
            # Get password:
            kubectl -n rook-ceph get secret rook-ceph-dashboard-password -o jsonpath="{['data']['password']}" | base64 -d
            # Port forward:
            kubectl port-forward -n rook-ceph svc/rook-ceph-mgr-dashboard 7000:7000
            # Or via ingress: https://ceph.atoca.house
            # Username: admin

          View Storage Classes:
            kubectl get storageclass
            # ceph-block (default) - RWO block storage for databases
            # ceph-filesystem - RWX shared filesystem for media
            # ceph-bucket - S3-compatible object storage

          ============================================================================
          Next Steps
          ============================================================================

          1. Change ArgoCD admin password (default is auto-generated)
          2. Monitor ArgoCD for application sync status
          3. Verify Ceph cluster is HEALTH_OK (may take 10-15 minutes)
          4. Configure ingress DNS records for exposed services
          5. Deploy applications via ArgoCD

          ============================================================================
          Documentation
          ============================================================================

          Repository structure:
            /infra/k8s/          - Infrastructure Helm charts by category
            /apps/               - Application deployments by category
            /argocd/             - ArgoCD parent apps and configuration
            /infra/talos/        - Talos OS configurations
            /infra/ansible/      - Ansible automation playbooks

          Useful resources:
            â€¢ Rook-Ceph docs: /infra/k8s/storage/rook-ceph-cluster/README.md
            â€¢ Talos docs: /infra/talos/README.md
            â€¢ Main README: /README.md

          ============================================================================
